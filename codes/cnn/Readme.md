## CNN classifier
Using the implementation provided by [Keras](https://keras.io/) </br>
Requirements: scipy, numpy, matplotlib, pandas, scikit-learn, keras, tensorflow

### Usage
1. To obtain boundaries for a test audio, run
```
python predict_boundaries.py path/to/audio/filename.wav
```
The predicted boundaries are saved to a log file at: ```./logs/CNN_test_log.txt```. The provided model is trained on all the songs and is located at: ```./saved_models/3_50``` . The folder name indicates that the model is trained on mel-spectrograms averaged using a *3s* window with *+-50* context frames.
The command line argument can also be a txt or csv file either in the format of the annotation files, or simply containing a column-list of filenames - boundaries will be predicted and saved for all the files. The filenames need not include the entire path, in which case, the path is set to the default value specified by the ```audio_dir``` variable in the ```params.py``` file (see below).

2. To perform training </br>
First run
```
python make_cv_dataset.py
```
This script generates and saves frame-wise mel-spectrograms containing the context frames and the corresponding labels for all the 20 songs. By default, no data augmentation is performed. To perform augmentation using pitch-shifts and audio-offsets, first ensure that pitch-shifted audios are available in a folder called ```pitch_shifted``` within the ```audio_dir```. Then set the ```audio_offset_list``` and ```pitch_shift_list``` variables in the ```params.py``` file to the set of offset/shift values. </br>

Then run
```
python run_cv.py
```

### Logs
* The boundary evaluation scores generated by ```run_cv.py``` are written to ```./logs/CNN_cv_log.txt```. The outputs include the tuple - (#Hits, #FP, #Boundaries), calculated at various peak-picking thresholds, for each fold. The final precision, recall and f-score values at each threshold value are also calculated and saved.
* The boundaries predicted by ```predict_boundaries.py``` are written to ```./logs/CNN_test_log.txt```. In case the ground truth boundaries are provided (in the format of the annotation files), the tuple (#Hits, #FP, #Boundaries) and the precision, recall and f-score values are also saved.

### Contents
* ```params.py```: Master file of all the hyperparameter values, directory and file paths, etc., and is imported by all other files.
* ```predict_boundaries.py```: obtain predictions on a test audio.
```make_cv_dataset.py```: Generates the mel-spectrogram of each audio, divides into chunks of a specified context duration, and saves each chunk as a ```.npy``` file. Each chunk is assigned a single label corresponding to the center frame. Labels are binary - 1 indicating boundary frame and 0 otherwise. 
Boundary labels are smeared - all frames in a neighbourhood of the manually annotated boundary are also marked boundary. 
The labels are stored in a separate dictionary with the filenames of the saved chunks as keys, which is also saved as a ```.npy``` file.
* ```run_cv.py```: Performs cross-validation on the 20-concert dataset.
