## Random Forest classifier
Using the implementation provided by [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#) </br>
Requirements: scipy, numpy, matplotlib, pandas, scikit-learn

### Usage
* To obtain boundaries for a test audio (whose features have been extracted), run
```
python predict_boundaries.py path/to/features/filename.mat
```
The predicted boundaries are saved to a log file at: ```./logs/RF_test_log.txt```. The provided model is trained on all the songs and is located at: ```./saved_models/all_3_20_100``` . The folder name indicates that the model is trained using *all* features, averaged using a *3s* window, using *20* trees, and *+-50* context frames.
The command line argument can also be a txt or csv file either in the format of the annotation files, or simply containing a column-list of filenames - boundaries will be predicted and saved for all the files. The filenames need not include the entire path, in which case, the path is set to the value specified in the ```params.py``` file (see below). </br> </br>

* To perform training, first ensure that features have been extracted for all the 20 songs. Then run
```
python make_cv_dataset.py
```
This script generates frame-level labels from ground truth boundaries and saves the features and labels in a format suitable for RF training. By default, target smearing is applied, but no data augmentation is performed. To perform augmentation using pitch-shifts and audio-offsets, first ensure that features have been extracted for all versions (see ). Then set the ```audio_offset_list``` and ```pitch_shift_list``` variables in the ```params.py``` file to the set of shift/offset values. </br>
Then, to perform the cross-validation, run
```
python run_cv.py
```

### Logs
* The boundary evaluation scores generated by ```run_cv.py``` are written to ```./logs/RF_cv_log.txt```. The outputs include the tuple - (#Hits, #FP, #Boundaries), calculated at various peak-picking thresholds, for each fold. The final precision, recall and f-score values at each threshold value are also calculated and saved.
* The boundaries predicted by ```predict_boundaries.py``` are written to ```./logs/RF_test_log.txt```. In case the ground truth boundaries are provided (in the format of the annotation files), the tuple (#Hits, #FP, #Boundaries) and the precision, recall and f-score values are also saved.

### Contents
* ```params.py```: master file of all hyperparameter values, directory and file paths, etc. (imported by all other files).
* ```predict_boundaries.py```: obtain predictions on the extracted features of a test audio.
* ```make_cv_dataset.py```: takes the features extracted using the MATLAB codes, makes the different feature subsets (as in the paper), and creates a dictionary
for each song containing the frame-wise features and target labels. The labels are binary - 1 indicating boundary frame and 0 otherwise. Boundary labels are smeared \- all frames in a neighbourhood of the manually annotated boundary are also marked boundary. The dictionaries are stored as ```.npy``` files.
* ```run_cv.py```: to perform cross-validation on the 20-concert dataset.
